{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pmlb import fetch_data, classification_dataset_names\n",
    "from scipy import stats\n",
    "\n",
    "import random as rd\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "                age     workclass        fnlwgt     education  education-num  \\\n",
      "count  48842.000000  48842.000000  4.884200e+04  48842.000000   48842.000000   \n",
      "mean      38.643585      3.870439  1.896641e+05     10.288420      10.078089   \n",
      "std       13.710510      1.464234  1.056040e+05      3.874492       2.570973   \n",
      "min       17.000000      0.000000  1.228500e+04      0.000000       1.000000   \n",
      "25%       28.000000      4.000000  1.175505e+05      9.000000       9.000000   \n",
      "50%       37.000000      4.000000  1.781445e+05     11.000000      10.000000   \n",
      "75%       48.000000      4.000000  2.376420e+05     12.000000      12.000000   \n",
      "max       90.000000      8.000000  1.490400e+06     15.000000      16.000000   \n",
      "\n",
      "       marital-status    occupation  relationship          race           sex  \\\n",
      "count    48842.000000  48842.000000  48842.000000  48842.000000  48842.000000   \n",
      "mean         2.618750      6.577700      1.443287      3.668052      0.668482   \n",
      "std          1.507703      4.230509      1.602151      0.845986      0.470764   \n",
      "min          0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%          2.000000      3.000000      0.000000      4.000000      0.000000   \n",
      "50%          2.000000      7.000000      1.000000      4.000000      1.000000   \n",
      "75%          4.000000     10.000000      3.000000      4.000000      1.000000   \n",
      "max          6.000000     14.000000      5.000000      4.000000      1.000000   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week  native-country  \\\n",
      "count  48842.000000  48842.000000    48842.000000    48842.000000   \n",
      "mean    1079.067626     87.502314       40.422382       36.749355   \n",
      "std     7452.019058    403.004552       12.391444        7.775343   \n",
      "min        0.000000      0.000000        1.000000        0.000000   \n",
      "25%        0.000000      0.000000       40.000000       39.000000   \n",
      "50%        0.000000      0.000000       40.000000       39.000000   \n",
      "75%        0.000000      0.000000       45.000000       39.000000   \n",
      "max    99999.000000   4356.000000       99.000000       41.000000   \n",
      "\n",
      "             target  \n",
      "count  48842.000000  \n",
      "mean       0.760718  \n",
      "std        0.426649  \n",
      "min        0.000000  \n",
      "25%        1.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n"
     ]
    }
   ],
   "source": [
    "from pmlb import fetch_data, classification_dataset_names\n",
    "adult_data = fetch_data('adult')\n",
    "print(len(classification_dataset_names))\n",
    "print(adult_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = fetch_data('adult',return_X_y = True) \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##get the best classfier\n",
    "def ETC_best(X,y):\n",
    "    depth =  X.shape[1]\n",
    "    param ={'n_estimators':range(10,71,10),'max_features':[0.05,0.1,0.15,0.2,0.3],'min_samples_split':[2,0.01,0.02,0.05,0.1],'min_samples_leaf':[1,0.005,0.01,0.02,0.05],'max_depth':[depth,int(math.sqrt(depth)),int(math.log2(depth))]}\n",
    "    gsearch= GridSearchCV(estimator =ExtraTreesClassifier(random_state=10), \n",
    "                       param_grid =param,scoring='roc_auc',cv=5, n_jobs = 5)\n",
    "    gsearch.fit(X,y)\n",
    "    best = gsearch.best_params_\n",
    "    ETC_best = ExtraTreesClassifier(random_state=10,n_estimators = best[\"n_estimators\"],max_features = best[\"max_features\"],min_samples_split = best[\"min_samples_split\"],\n",
    "                                    min_samples_leaf = best[\"min_samples_leaf\"])\n",
    "    return(ETC_best)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#depth =  X.shape[1]\n",
    "#param ={'n_estimators':range(10,71,10),'max_features':[0.05,0.1,0.15,0.2,0.3],'min_samples_split':[2,0.01,0.02,0.05,0.1],'min_samples_leaf':[1,0.005,0.01,0.02,0.05],'max_depth':[depth,int(math.sqrt(depth)),int(math.log2(depth))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': range(10, 71, 10),\n",
       " 'max_features': [0.05, 0.1, 0.15, 0.2, 0.3],\n",
       " 'min_samples_split': [2, 0.01, 0.02, 0.05, 0.1],\n",
       " 'min_samples_leaf': [1, 0.005, 0.01, 0.02, 0.05],\n",
       " 'max_depth': [14, 3, 3]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2625"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extra_err_bias_var_clc(X,y,clc,n = 100,train_size_p = 0.6,pool_size_p = 0.15,test_size_p = 0.15):\n",
    "    pool_X, test_X, pool_y, test_y = train_test_split(X, y,train_size = train_size_p ,test_size = test_size_p)\n",
    "    clc.n_jobs = 6\n",
    "    train_size = math.ceil(len(y)*pool_size_p)\n",
    "    test_size = len(test_y)\n",
    "    num_generate = n\n",
    "    all_pred = np.zeros((num_generate,test_size),dtype = np.int)\n",
    "    train_pred = np.zeros((num_generate,train_size),dtype = np.int)\n",
    "    train_err = np.zeros(num_generate,dtype = np.float)\n",
    "    test_err = np.zeros(num_generate,dtype = np.float)\n",
    "    for i in range(0,num_generate):\n",
    "        index = rd.sample(range(0,len(pool_y)) ,k = train_size)\n",
    "        learn_X = pool_X[index]\n",
    "        learn_y = pool_y[index]\n",
    "        fit_model = clc.fit(learn_X,learn_y)\n",
    "        \n",
    "        train_pred[i] = fit_model.predict(learn_X)\n",
    "        train_err[i] = (train_pred[i] != learn_y).mean()\n",
    "        \n",
    "        pred = fit_model.predict(test_X)\n",
    "        all_pred[i] = pred\n",
    "        test_err[i] = (pred!= test_y).mean()\n",
    "        \n",
    "        \n",
    "    avr_test_err = np.mean(test_err)\n",
    "    std_test_err = np.std(test_err)\n",
    "    avr_train_err = np.mean(train_err)\n",
    "    std_train_err = np.std(train_err)\n",
    "\n",
    "    main_pred = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis = 0, arr = all_pred)\n",
    "    bias = sum(test_y != main_pred)/len(test_y)\n",
    "    Var=np.zeros(num_generate, dtype=np.float)\n",
    "    for i in range(num_generate):\n",
    "        Var[i]=sum(all_pred[i]!=main_pred)/len(main_pred)\n",
    "    var=Var.mean()\n",
    "    stat_out = [bias,var,avr_train_err,std_train_err,avr_test_err,std_test_err]\n",
    "    return stat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Extra_mul_par_com_clc(X,y,n = 100,train_size_p = 0.6,pool_size_p = 0.15,test_size_p = 0.15):\n",
    "    stat_n_estimators = []\n",
    "    for i in range(10,70,10):\n",
    "        clc = ExtraTreesClassifier(random_state = 10,n_jobs = 6,n_estimators = i)\n",
    "        stat_n_estimators_i = Extra_err_bias_var_clc(X,y,clc)\n",
    "        stat_n_estimators.append(stat_n_estimators_i)\n",
    "    stat_max_features = []\n",
    "    for i in [0.05,0.1,0.15,0.2,0.3]:\n",
    "        clc = ExtraTreesClassifier(random_state = 10,n_jobs = 6,max_features = i)\n",
    "        stat_max_features_i = Extra_err_bias_var_clc(X,y,clc)\n",
    "        stat_max_features.append(stat_max_features_i)\n",
    "    stat_min_samples_split = []\n",
    "    for i in range(10,70,10):\n",
    "        clc = ExtraTreesClassifier(random_state = 10,n_jobs = 6,min_samples_split = i)\n",
    "        stat_min_samples_split_i = Extra_err_bias_var_clc(X,y,clc)\n",
    "        stat_min_samples_split.append(stat_min_samples_split_i)\n",
    "    stat_min_samples_leaf = []\n",
    "    for i in [0.05,0.1,0.15,0.2,0.3]:\n",
    "        clc = ExtraTreesClassifier(random_state = 10,n_jobs = 6,min_samples_leaf = i)\n",
    "        stat_min_samples_leaf_i = Extra_err_bias_var_clc(X,y,clc)\n",
    "        stat_min_samples_leaf.append(stat_min_samples_leaf_i)\n",
    "    depth =  X.shape[1]\n",
    "    stat_max_depth = []\n",
    "    depth =  X.shape[1]\n",
    "    for i in [depth,int(math.sqrt(depth)),int(math.log2(depth))]:\n",
    "        clc = ExtraTreesClassifier(random_state = 10,n_jobs = 6,max_depth = i)\n",
    "        stat_max_depth_i = Extra_err_bias_var_clc(X,y,clc)\n",
    "        stat_max_depth.append(stat_max_depth_i)\n",
    "    stat_out = [stat_n_estimators,stat_max_features,stat_min_samples_split,stat_min_samples_leaf,stat_max_depth]\n",
    "    return(stat_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bvr_cal(train,pool,test):\n",
    "    bias_variance_err = []\n",
    "    for classification_dataset in classification_dataset_names:\n",
    "        X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "        y = y - min(y) # exists y = -1 etc\n",
    "        stat =Extra_mul_par_com_clc(X,y,train,pool,test)\n",
    "        bias_variance_err.append(stat)\n",
    "    return bias_variance_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_p_c = bvr_cal(0.6,0.15,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"out1pc.npy\",stat_p_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
